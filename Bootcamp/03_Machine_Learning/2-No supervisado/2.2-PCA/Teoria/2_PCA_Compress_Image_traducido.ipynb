{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *PCA* - Comprimir imágenes\n",
    "\n",
    "Una imagen digital estandar se obtiene apilando matrices de píxeles rojos, azules y verdes de intensidades comprendidas entre 0 y 255.\n",
    "\n",
    "<img src=\"img/RGB.png\">\n",
    "\n",
    "Una imagen en escala de grises no contiene color, sino sólo tonos de gris. La intensidad de los píxeles de una imagen en escala de grises varía del negro (intensidad 0) al blanco (intensidad total 255), lo que la convierte en lo que solemos llamar una imagen en blanco y negro.\n",
    "\n",
    "Digits dataset es un conjunto de datos de imágenes en escala de grises de dígitos manuscritos que contiene 1.797 imágenes de 8×8 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo `sklearn.datasets` agiliza la importación de datos de dígitos importando de él la clase `load_digits`. La forma de los datos de dígitos es (1797, 64). Los píxeles de 8×8 se aplanan para crear un vector de longitud 64 para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sample = data[100,:].reshape(8,8)\n",
    "image_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_sample, cmap='binary')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, utilizando *PCA*, reduzcamos las dimensiones de la imagen de 64 a sólo 2 para poder visualizar el conjunto de datos utilizando un gráfico de dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "converted_data = pca.fit_transform(digits.data)\n",
    "\n",
    "display(\n",
    "    pca.explained_variance_ratio_,\n",
    "    pca.explained_variance_ratio_.cumsum(), \n",
    "    converted_data.shape\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos pasar un valor flotante menor que 1 en lugar de un número entero. Por ejemplo, `PCA(0.90)` significa que el algoritmo encontrará los componentes principales que explican el 90% de la varianza de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize = (10,6))\n",
    "c_map = plt.cm.get_cmap('jet', 10)\n",
    "plt.scatter(converted_data[:, 0], converted_data[:, 1], s = 15,\n",
    "            cmap = c_map , c = digits.target)\n",
    "plt.colorbar()\n",
    "plt.xlabel('PC-1') , plt.ylabel('PC-2')\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una aplicación interesante del PCA es la compresión de imágenes. Echemos un vistazo a cómo podemos lograr esto con python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # !pip install opencv-python\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/my_doggo_sample.jpeg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "793*1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la imagen en los arrays R, G, B.\n",
    "blue, green, red = cv2.split(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_compressed = cv2.merge([red,green,blue])\n",
    "plt.imshow(img_not_compressed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_compressed = cv2.merge([blue, green, red])\n",
    "plt.imshow(img_not_compressed);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV dividirá en canales Azul, Verde y Rojo en lugar de Rojo, Azul y Verde. Tenga mucho cuidado con la secuencia aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el PCA con las 20 primeras componentes principales.\n",
    "pca = PCA(20)\n",
    " \n",
    "# Aplicando al canal rojo y luego aplicando la transformada inversa a la matriz transformada.\n",
    "red_transformed = pca.fit_transform(red)\n",
    "print('red_transformed.shape:', red_transformed.shape)\n",
    "red_inverted = pca.inverse_transform(red_transformed)\n",
    "print('red_inverted.shape:', red_inverted.shape)\n",
    "\n",
    "# Aplicando al canal verde y luego aplicando la transformada inversa a la matriz transformada.\n",
    "green_transformed = pca.fit_transform(green)\n",
    "print('green_transformed.shape:', green_transformed.shape)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    "print('green_inverted.shape:', green_inverted.shape)\n",
    " \n",
    "# Aplicando al canal azul y luego aplicando la transformada inversa a la matriz transformada.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "print('blue_transformed.shape:', blue_transformed.shape)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "print('blue_inverted.shape:', blue_inverted.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de reconstrucción de las dimensiones originales a partir de las dimensiones reducidas, se pierde algo de información, ya que sólo conservamos los componentes principales seleccionados, 20 en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_compressed = (cv2.merge([red_inverted, green_inverted, blue_inverted])).astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apilando las matrices invertidas usando la función `dstack`. Aquí es importante especificar el tipo de datos de nuestras matrices, ya que la mayoría de las imágenes son de 8 bits. Cada píxel está representado por un byte de 8 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_compressed);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior es el que obtenemos cuando consideramos sólo 20 componentes principales.\n",
    "\n",
    "Si aumentamos el número de componentes principales, la imagen de salida será más clara.\n",
    "\n",
    "1. Ahora comprueba con cuántos componentes principales tus ojos no pueden ver la diferencia con el original.\n",
    "\n",
    "1. El perro no debería ser tan azul, ¡arréglalo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el PCA con las 300 primeras componentes principales.\n",
    "pca = PCA(300)\n",
    " \n",
    "# Aplicando al canal rojo y luego aplicando la transformada inversa a la matriz transformada.\n",
    "red_transformed = pca.fit_transform(red)\n",
    "print('red_transformed.shape:', red_transformed.shape)\n",
    "red_inverted = pca.inverse_transform(red_transformed)\n",
    "print('red_inverted.shape:', red_inverted.shape)\n",
    "\n",
    "# Aplicando al canal verde y luego aplicando la transformada inversa a la matriz transformada.\n",
    "green_transformed = pca.fit_transform(green)\n",
    "print('green_transformed.shape:', green_transformed.shape)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    "print('green_inverted.shape:', green_inverted.shape)\n",
    " \n",
    "# Aplicando al canal azul y luego aplicando la transformada inversa a la matriz transformada.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "print('blue_transformed.shape:', blue_transformed.shape)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "print('blue_inverted.shape:', blue_inverted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_compressed = (cv2.merge([red_transformed, green_transformed, blue_transformed])).astype(np.uint8)\n",
    "\n",
    "#observamos la imagen comprimida\n",
    "plt.imshow(img_compressed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.cumsum()[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.cumsum()[299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el PCA con las 280 primeras componentes principales.\n",
    "pca = PCA(280)\n",
    " \n",
    "# Aplicando al canal rojo y luego aplicando la transformada inversa a la matriz transformada.\n",
    "red_transformed = pca.fit_transform(red)\n",
    "print('red_transformed.shape:', red_transformed.shape)\n",
    "red_inverted = pca.inverse_transform(red_transformed)\n",
    "print('red_inverted.shape:', red_inverted.shape)\n",
    "\n",
    "# Aplicando al canal verde y luego aplicando la transformada inversa a la matriz transformada.\n",
    "green_transformed = pca.fit_transform(green)\n",
    "print('green_transformed.shape:', green_transformed.shape)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    "print('green_inverted.shape:', green_inverted.shape)\n",
    " \n",
    "# Aplicando al canal azul y luego aplicando la transformada inversa a la matriz transformada.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "print('blue_transformed.shape:', blue_transformed.shape)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "print('blue_inverted.shape:', blue_inverted.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
